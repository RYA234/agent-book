{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gzo38EvYzht"
      },
      "source": [
        "# 5. LangChain Expression Language（LCEL）徹底解説\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
          "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
          "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
          "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
        },
        "id": "TePa8DzTYzhu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TnLdbbooYzhu",
        "outputId": "e5361523-a426-44ae-e1d7-6a23cbc1f4c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core==0.3.0 in /usr/local/lib/python3.12/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-openai==0.2.0 in /usr/local/lib/python3.12/dist-packages (0.2.0)\n",
            "Requirement already satisfied: langchain-community==0.3.0 in /usr/local/lib/python3.12/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pydantic==2.10.6 in /usr/local/lib/python3.12/dist-packages (2.10.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (4.15.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.0) (1.108.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.0) (0.11.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.0) (2.0.43)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.0) (3.12.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.0) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.0) (0.3.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.0) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.0) (2.10.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.0) (2.32.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.10.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.10.6) (2.27.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.0) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community==0.3.0) (0.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.0) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community==0.3.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community==0.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community==0.3.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community==0.3.0) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.0) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-core==0.3.0 langchain-openai==0.2.0 langchain-community==0.3.0 pydantic==2.10.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXWzxJxcYzhu"
      },
      "source": [
        "## 5.1. Runnable と RunnableSequence―LCEL の最も基本的な構成要素\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:12.290335Z",
          "iopub.status.busy": "2024-06-28T02:33:12.290156Z",
          "iopub.status.idle": "2024-06-28T02:33:12.344661Z",
          "shell.execute_reply": "2024-06-28T02:33:12.344241Z"
        },
        "id": "lm_4I6UbYzhv"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ユーザーが入力した家具のレシピを考えてください。\"),\n",
        "        (\"human\", \"{furniture}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:12.346689Z",
          "iopub.status.busy": "2024-06-28T02:33:12.346510Z",
          "iopub.status.idle": "2024-06-28T02:33:21.108437Z",
          "shell.execute_reply": "2024-06-28T02:33:21.108007Z"
        },
        "id": "No3QZCYlYzhv",
        "outputId": "f97a99d8-a30c-4f3d-8fcd-7d6d6f9915dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "椅子のレシピを考えてみましょう。以下は、シンプルな木製の椅子を作るための基本的なレシピです。\n",
            "\n",
            "### 材料\n",
            "- 木材（例：パイン材、オーク材など）\n",
            "  - 座面用：1枚（約40cm x 40cm）\n",
            "  - 脚用：4本（約80cmの長さ）\n",
            "  - 背もたれ用：1枚（約40cm x 20cm）\n",
            "- 木工用接着剤\n",
            "- ネジ（木ネジ）\n",
            "- サンドペーパー（粗目と細目）\n",
            "- 塗料またはニス（オプション）\n",
            "\n",
            "### 工具\n",
            "- ノコギリ\n",
            "- ドリル\n",
            "- スクリュードライバー\n",
            "- 定規\n",
            "- 鉛筆\n",
            "\n",
            "### 作り方\n",
            "\n",
            "1. **木材のカット**:\n",
            "   - 座面用の木材を40cm x 40cmにカットします。\n",
            "   - 脚用の木材を80cmに4本カットします。\n",
            "   - 背もたれ用の木材を40cm x 20cmにカットします。\n",
            "\n",
            "2. **脚の取り付け**:\n",
            "   - 座面の裏側に脚を取り付けます。各脚の端を座面の角に合わせ、木ネジで固定します。脚はしっかりと固定されるように、接着剤も併用すると良いでしょう。\n",
            "\n",
            "3. **背もたれの取り付け**:\n",
            "   - 背もたれを座面の後ろに取り付けます。背もたれの下端を座面の後ろ側に合わせ、木ネジで固定します。\n",
            "\n",
            "4. **仕上げ**:\n",
            "   - 椅子全体をサンドペーパーで滑らかにします。特に角や接合部は丁寧に仕上げましょう。\n",
            "   - お好みで塗料やニスを塗り、乾燥させます。\n",
            "\n",
            "5. **完成**:\n",
            "   - すべてが乾いたら、椅子の完成です。しっかりとした安定性を確認し、使用してみてください。\n",
            "\n",
            "このレシピは基本的な椅子の作り方ですが、デザインやサイズはお好みに応じてアレンジできます。安全に作業を行い、楽しいDIYをお楽しみください！\n"
          ]
        }
      ],
      "source": [
        "prompt_value = prompt.invoke({\"furniture\": \"椅子\"})\n",
        "ai_message = model.invoke(prompt_value)\n",
        "output = output_parser.invoke(ai_message)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:21.110332Z",
          "iopub.status.busy": "2024-06-28T02:33:21.110173Z",
          "iopub.status.idle": "2024-06-28T02:33:21.112634Z",
          "shell.execute_reply": "2024-06-28T02:33:21.112238Z"
        },
        "id": "UfiIXEJAYzhv"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:21.114678Z",
          "iopub.status.busy": "2024-06-28T02:33:21.114418Z",
          "iopub.status.idle": "2024-06-28T02:33:26.539851Z",
          "shell.execute_reply": "2024-06-28T02:33:26.539250Z"
        },
        "id": "OAlWtsqIYzhv",
        "outputId": "33b95e53-2cce-4ca4-d349-c7e091e625df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "マインクラフトでカレーを作るためのレシピを考えてみました。以下の材料を用意してください。\n",
            "\n",
            "### カレーのレシピ\n",
            "\n",
            "**材料:**\n",
            "- 小麦の種 × 1\n",
            "- にんじん × 1\n",
            "- ポテト × 1\n",
            "- 鶏肉 × 1\n",
            "- 水バケツ × 1\n",
            "\n",
            "**作り方:**\n",
            "1. **小麦の種**を使って、パンを作ります。\n",
            "2. **にんじん**と**ポテト**をそれぞれ収穫します。\n",
            "3. **鶏肉**を焼いて、料理します。\n",
            "4. **水バケツ**を使って、鍋の代わりに水を加えます。\n",
            "\n",
            "これらの材料を組み合わせて、カレーを作ることができます。もちろん、マインクラフトの世界では実際にカレーは作れませんが、想像力を働かせて楽しんでください！\n"
          ]
        }
      ],
      "source": [
        "output = chain.invoke({\"furniture\": \"ベッド\"})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykdz1fTxYzhv"
      },
      "source": [
        "### Runnable の実行方法―invoke・stream・batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:26.545129Z",
          "iopub.status.busy": "2024-06-28T02:33:26.544905Z",
          "iopub.status.idle": "2024-06-28T02:33:32.478679Z",
          "shell.execute_reply": "2024-06-28T02:33:32.478134Z"
        },
        "id": "6bwsOBOLYzhv"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | output_parser\n",
        "\n",
        "for chunk in chain.stream({\"furniture\": \"椅子\"}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:32.480592Z",
          "iopub.status.busy": "2024-06-28T02:33:32.480406Z",
          "iopub.status.idle": "2024-06-28T02:33:38.976064Z",
          "shell.execute_reply": "2024-06-28T02:33:38.974376Z"
        },
        "id": "xESm7f38Yzhw",
        "outputId": "a9629adc-025f-46db-d511-d78fa02e1fcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['マインクラフトでカレーを作るためのレシピを考えてみました。以下の材料を用意してください。\\n\\n### カレーのレシピ\\n\\n#### 材料:\\n- 小麦の種 × 1\\n- にんじん × 1\\n- ポテト × 1\\n- 鶏肉 × 1\\n- 水バケツ × 1\\n\\n#### 作り方:\\n1. **鍋を作る**: 鉄インゴットを3つ使って、かまどを作ります。\\n2. **材料を調理する**:\\n   - 鶏肉をかまどで焼いて、焼き鳥を作ります。\\n   - ポテトをかまどで焼いて、焼きポテトを作ります。\\n3. **カレーを作る**:\\n   - 作業台を使って、以下のように配置します。\\n     - 上段: 焼き鳥、焼きポテト\\n     - 中段: にんじん\\n     - 下段: 小麦の種\\n     - 右側: 水バケツ\\n4. **完成**: 作業台でレシピを組み合わせると、カレーが完成します！\\n\\nこのカレーは、食べると満腹度が回復する特別な料理です。マインクラフトの世界で楽しんでください！', 'マインクラフトの世界で「うどん」を作るためのレシピを考えてみました。以下の材料を使って、うどんを作ることができます。\\n\\n### うどんのレシピ\\n\\n**材料:**\\n- 小麦の種 × 2\\n- 水バケツ × 1\\n- きのこ × 1（お好みで）\\n- 鶏肉または豚肉 × 1（お好みで）\\n- 塩（砂利を使って作成）\\n\\n**作り方:**\\n1. **小麦の種を育てる**: 小麦の種を畑に植えて成長させ、小麦を収穫します。\\n2. **水を用意する**: 水バケツを用意し、鍋の代わりに使います。\\n3. **具材を用意する**: きのこや肉を用意します。肉は焼いておくと良いでしょう。\\n4. **調理**: 小麦を使ってうどんの生地を作り、水と一緒に鍋で煮るイメージで調理します。\\n5. **盛り付け**: できたうどんにきのこや肉をトッピングして完成です。\\n\\nこのレシピはマインクラフトの実際のゲームメカニクスにはないものですが、想像力を働かせて楽しんでみてください！']\n"
          ]
        }
      ],
      "source": [
        "chain = prompt | model | output_parser\n",
        "\n",
        "outputs = chain.batch([{\"furniture\": \"椅子\"}, {\"furniture\": \"机\"}])\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M1qJWdrYzhw"
      },
      "source": [
        "### LCEL の「|」で様々な Runnable を連鎖させる\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:38.984366Z",
          "iopub.status.busy": "2024-06-28T02:33:38.983620Z",
          "iopub.status.idle": "2024-06-28T02:33:39.072077Z",
          "shell.execute_reply": "2024-06-28T02:33:39.071585Z"
        },
        "id": "kg8-8gRLYzhw"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:39.073954Z",
          "iopub.status.busy": "2024-06-28T02:33:39.073805Z",
          "iopub.status.idle": "2024-06-28T02:33:39.076746Z",
          "shell.execute_reply": "2024-06-28T02:33:39.076291Z"
        },
        "id": "9LDFBWxkYzhw"
      },
      "outputs": [],
      "source": [
        "cot_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ユーザーの質問にステップバイステップで回答してください。\"),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "cot_chain = cot_prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:39.078597Z",
          "iopub.status.busy": "2024-06-28T02:33:39.078287Z",
          "iopub.status.idle": "2024-06-28T02:33:39.080804Z",
          "shell.execute_reply": "2024-06-28T02:33:39.080464Z"
        },
        "id": "y4aXvdCIYzhw"
      },
      "outputs": [],
      "source": [
        "summarize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ステップバイステップで考えた回答から結論だけ抽出してください。\"),\n",
        "        (\"human\", \"{text}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "summarize_chain = summarize_prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:39.082487Z",
          "iopub.status.busy": "2024-06-28T02:33:39.082344Z",
          "iopub.status.idle": "2024-06-28T02:33:42.144944Z",
          "shell.execute_reply": "2024-06-28T02:33:42.144538Z"
        },
        "id": "3coY80beYzhx",
        "outputId": "2328c486-c99a-44cd-e492-b97550e5dfaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "10 + 2 * 3 の答えは **16** です。\n"
          ]
        }
      ],
      "source": [
        "# cot_summarize_chain = cot_chain | summarize_chain\n",
        "cot_summarize_chain = summarize_chain\n",
        "output = cot_summarize_chain.invoke({\"text\": \"10 + 2 * 3\"})\n",
        "print(\"答えのみの場合\")\n",
        "print(output)\n",
        "\n",
        "cot_summarize_chain = cot_chain | summarize_chain\n",
        "output = cot_summarize_chain.invoke({\"question\": \"10 + 2 * 3\"})\n",
        "print(\"途中式も有り\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rY9XCcGYzhx"
      },
      "source": [
        "## 5.2. RunnableLambda―任意の関数を Runnable にする\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:42.146898Z",
          "iopub.status.busy": "2024-06-28T02:33:42.146736Z",
          "iopub.status.idle": "2024-06-28T02:33:42.204154Z",
          "shell.execute_reply": "2024-06-28T02:33:42.203681Z"
        },
        "id": "JhzBCFZCYzhx"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 日本人の場合\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# アシスタントの出身国を変更して結果を確認する\n",
        "\n",
        "# 日本人の場合\n",
        "prompt_japanese = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are japanese helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "# 韓国人の場合\n",
        "prompt_korean = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are korean helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "# 中国人の場合\n",
        "prompt_chinese = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are chinese helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ベトナム人の場合\n",
        "prompt_vietonam = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are vietnamese helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# キューバ人の場合\n",
        "prompt_cuban = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are cuban helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# フランス人の場合\n",
        "prompt_french = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are french helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:42.206082Z",
          "iopub.status.busy": "2024-06-28T02:33:42.205909Z",
          "iopub.status.idle": "2024-06-28T02:33:43.030226Z",
          "shell.execute_reply": "2024-06-28T02:33:43.029756Z"
        },
        "id": "PxfSySkkYzhx",
        "outputId": "49f3143b-6ec5-4b3e-c3f8-3b01446e72ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "こんにちは！どのようにお手伝いできますか？\n",
            "안녕하세요! 어떻게 도와드릴까요?\n",
            "你好！有什么我可以帮助你的吗？\n",
            "XIN CHÀO! HOW CAN I ASSIST YOU TODAY?\n",
            "¡HOLA! ¿CÓMO PUEDO AYUDARTE HOY?\n",
            "BONJOUR ! COMMENT PUIS-JE VOUS AIDER AUJOURD'HUI ?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "\n",
        "def upper(text: str) -> str:\n",
        "    return text.upper()\n",
        "\n",
        "\n",
        "# 日本\n",
        "chain = prompt_japanese | model | output_parser | RunnableLambda(upper)\n",
        "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(ai_message)\n",
        "\n",
        "# 韓国\n",
        "chain = prompt_korean | model | output_parser | RunnableLambda(upper)\n",
        "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(ai_message)\n",
        "\n",
        "# 中国\n",
        "chain = prompt_chinese | model | output_parser | RunnableLambda(upper)\n",
        "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(ai_message)\n",
        "\n",
        "# ベトナム\n",
        "chain = prompt_vietonam | model | output_parser | RunnableLambda(upper)\n",
        "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(ai_message)\n",
        "\n",
        "# キューバ\n",
        "chain = prompt_cuban | model | output_parser | RunnableLambda(upper)\n",
        "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(ai_message)\n",
        "\n",
        "#　フランス\n",
        "chain = prompt_french | model | output_parser | RunnableLambda(upper)\n",
        "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(ai_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDWJxPbpYzhx"
      },
      "source": [
        "### chain デコレーターを使った RunnableLambda の実装\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:43.032211Z",
          "iopub.status.busy": "2024-06-28T02:33:43.032048Z",
          "iopub.status.idle": "2024-06-28T02:33:43.501555Z",
          "shell.execute_reply": "2024-06-28T02:33:43.499283Z"
        },
        "id": "Y4GoOxYeYzhx",
        "outputId": "1b93aa54-f38f-4f4d-f722-68324df77a77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HELLO! HOW CAN I ASSIST YOU TODAY?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import chain\n",
        "\n",
        "\n",
        "@chain\n",
        "def upper(text: str) -> str:\n",
        "    return text.upper()\n",
        "\n",
        "# 記述を簡易にすることができる\n",
        "# デコレータを使う前　chain = prompt_french | model | output_parser | RunnableLambda(upper)\n",
        "chain = prompt | model | output_parser | upper\n",
        "\n",
        "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(ai_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfGqLCa0Yzhx"
      },
      "source": [
        "### RunnableLambda への自動変換\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:43.508518Z",
          "iopub.status.busy": "2024-06-28T02:33:43.508321Z",
          "iopub.status.idle": "2024-06-28T02:33:43.511080Z",
          "shell.execute_reply": "2024-06-28T02:33:43.510672Z"
        },
        "id": "PgB1oPubYzhx"
      },
      "outputs": [],
      "source": [
        "# 書き方が変わるだけ？\n",
        "def upper(text: str) -> str:\n",
        "    return text.upper()\n",
        "\n",
        "\n",
        "chain = prompt | model | output_parser | upper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:43.512885Z",
          "iopub.status.busy": "2024-06-28T02:33:43.512594Z",
          "iopub.status.idle": "2024-06-28T02:33:43.961318Z",
          "shell.execute_reply": "2024-06-28T02:33:43.960803Z"
        },
        "id": "0kX_ClQsYzhx",
        "outputId": "49c2eefe-9592-4cbc-8b4c-972873ae29a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HELLO! HOW CAN I ASSIST YOU TODAY?\n"
          ]
        }
      ],
      "source": [
        "ai_message = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(ai_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMFjVsK2Yzhx"
      },
      "source": [
        "### Runnable の入力の型と出力の型に注意\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:43.963174Z",
          "iopub.status.busy": "2024-06-28T02:33:43.963026Z",
          "iopub.status.idle": "2024-06-28T02:33:43.965674Z",
          "shell.execute_reply": "2024-06-28T02:33:43.965305Z"
        },
        "id": "KodXukJBYzhy"
      },
      "outputs": [],
      "source": [
        "def upper(text: str) -> str:\n",
        "    return text.upper()\n",
        "\n",
        "\n",
        "chain = prompt | model | upper\n",
        "\n",
        "# 以下のコードを実行するとエラーになります\n",
        "# output = chain.invoke({\"input\": \"Hello!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:43.967542Z",
          "iopub.status.busy": "2024-06-28T02:33:43.967246Z",
          "iopub.status.idle": "2024-06-28T02:33:44.531734Z",
          "shell.execute_reply": "2024-06-28T02:33:44.531210Z"
        },
        "id": "3ppHmfBpYzhy"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | StrOutputParser() | upper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFp9pyWrYzhy"
      },
      "outputs": [],
      "source": [
        "output = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lummwnm0Yzhy"
      },
      "source": [
        "### （コラム）独自の関数を stream に対応させたい場合\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:44.533838Z",
          "iopub.status.busy": "2024-06-28T02:33:44.533678Z",
          "iopub.status.idle": "2024-06-28T02:33:45.353621Z",
          "shell.execute_reply": "2024-06-28T02:33:45.353115Z"
        },
        "id": "fygpaBaWYzhy",
        "outputId": "f8b1c147-deeb-4547-987a-cffe92779b01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HELLO! HOW CAN I ASSIST YOU TODAY?"
          ]
        }
      ],
      "source": [
        "from typing import Iterator\n",
        "\n",
        "\n",
        "def upper(input_stream: Iterator[str]) -> Iterator[str]:\n",
        "    for text in input_stream:\n",
        "        yield text.upper()\n",
        "\n",
        "\n",
        "chain = prompt | model | StrOutputParser() | upper\n",
        "\n",
        "for chunk in chain.stream({\"input\": \"Hello!\"}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrtTKxV-Yzhy"
      },
      "source": [
        "## 5.3. RunnableParallel―複数の Runnable を並列で処理する\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:45.355560Z",
          "iopub.status.busy": "2024-06-28T02:33:45.355402Z",
          "iopub.status.idle": "2024-06-28T02:33:45.407879Z",
          "shell.execute_reply": "2024-06-28T02:33:45.407407Z"
        },
        "id": "Lvu7zHPVYzhy"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:45.409670Z",
          "iopub.status.busy": "2024-06-28T02:33:45.409524Z",
          "iopub.status.idle": "2024-06-28T02:33:45.412232Z",
          "shell.execute_reply": "2024-06-28T02:33:45.411889Z"
        },
        "id": "gBjwIYBpYzhy"
      },
      "outputs": [],
      "source": [
        "optimistic_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"あなたは楽観主義者です。ユーザーの入力に対して楽観的な意見をください。\"),\n",
        "        (\"human\", \"{topic}\"),\n",
        "    ]\n",
        ")\n",
        "optimistic_chain = optimistic_prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:45.414087Z",
          "iopub.status.busy": "2024-06-28T02:33:45.413807Z",
          "iopub.status.idle": "2024-06-28T02:33:45.416778Z",
          "shell.execute_reply": "2024-06-28T02:33:45.416359Z"
        },
        "id": "2Ng8KcKmYzhz"
      },
      "outputs": [],
      "source": [
        "pessimistic_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"あなたは悲観主義者です。ユーザーの入力に対して悲観的な意見をください。\"),\n",
        "        (\"human\", \"{topic}\"),\n",
        "    ]\n",
        ")\n",
        "pessimistic_chain = pessimistic_prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:45.418636Z",
          "iopub.status.busy": "2024-06-28T02:33:45.418458Z",
          "iopub.status.idle": "2024-06-28T02:33:48.115947Z",
          "shell.execute_reply": "2024-06-28T02:33:48.115444Z"
        },
        "id": "bjTrsKj-Yzhz",
        "outputId": "7b0738ef-2ce1-4b60-8f53-6d544a062755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'optimistic_opinion': '生成AIの進化は本当に素晴らしいですね！技術が進むことで、私たちの生活がより便利で豊かになる可能性が広がっています。クリエイティブな作業や問題解決の手助けをしてくれるAIが増えてきて、私たちのアイデアを実現するためのパートナーとして活躍しています。これからも新しい発見や革新が続くことで、私たちの未来はますます明るくなるでしょう！どんな素晴らしいことが待っているのか、ワクワクしますね！',\n",
            " 'pessimistic_opinion': '生成AIの進化は確かに目覚ましいものですが、その裏には多くの懸念が潜んでいます。技術が進化することで、私たちの仕事が奪われたり、情報の信頼性が低下したりするリスクが高まっています。さらに、AIが生成するコンテンツが人間の創造性を脅かし、私たちの思考や感情に悪影響を及ぼす可能性もあります。結局のところ、便利さの裏には常に危険が潜んでいるのです。'}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "parallel_chain = RunnableParallel(\n",
        "    {\n",
        "        \"optimistic_opinion\": optimistic_chain,\n",
        "        \"pessimistic_opinion\": pessimistic_chain,\n",
        "    }\n",
        ")\n",
        "\n",
        "output = parallel_chain.invoke({\"topic\": \"生成AIの進化について\"})\n",
        "pprint.pprint(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "# 心の中の天使と悪魔から意見を出してもらう\n",
        "# 心の中の悪魔\n",
        "devil_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\"あなたは心の中の悪魔です。ユーザの入力に対して道徳的ではない意見をください。\"),\n",
        "        (\"human\",\"{topic}\"),\n",
        "    ]\n",
        ")\n",
        "devil_chain = devil_prompt | model | output_parser\n",
        "\n",
        "# 心の中の天使\n",
        "angel_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\"あなたは心の中の天使です。ユーザの入力に対して道徳的な意見をください。\"),\n",
        "        (\"human\",\"{topic}\"),\n",
        "    ]\n",
        ")\n",
        "angel_chain = angel_prompt | model | output_parser\n",
        "\n",
        "moracle_chain = RunnableParallel(\n",
        "    {\n",
        "        \"devil_chain\": devil_chain,\n",
        "        \"angel_chain\": angel_chain,\n",
        "    }\n",
        ")\n",
        "output = moracle_chain.invoke({\"topic\": \"道端に財布が落ちていた。どうしたら良い？\"})\n",
        "pprint.pprint(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "dGOK1UzaxmTY",
        "outputId": "1631ce61-2f3e-4a19-d227-b8a39a63aaf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'angel_chain': '道端に落ちている財布を見つけた場合、まずはその財布の持ち主を探すことが大切です。以下のステップを考えてみてください。\\n'\n",
            "                '\\n'\n",
            "                '1. **周囲を確認する**: '\n",
            "                '財布の近くに持ち主がいないか、周囲を見回してみましょう。もし持ち主が近くにいる場合、直接返すことができます。\\n'\n",
            "                '\\n'\n",
            "                '2. **中身を確認する**: '\n",
            "                '財布の中に連絡先や身分証明書が入っている場合、それを使って持ち主に連絡を取ることができます。ただし、個人情報を他人に見せないように注意しましょう。\\n'\n",
            "                '\\n'\n",
            "                '3. **警察に届ける**: '\n",
            "                '持ち主が見つからない場合は、最寄りの警察署に届けるのが良いでしょう。法律的にも、落とし物は警察に届けることが求められています。\\n'\n",
            "                '\\n'\n",
            "                '4. **善意を持って行動する**: '\n",
            "                '財布を見つけたことをきっかけに、他人の物を大切にする気持ちを持ち続けることが大切です。道徳的に正しい行動を選ぶことで、社会全体がより良い方向に向かうことができます。\\n'\n",
            "                '\\n'\n",
            "                'あなたの行動が、持ち主にとっても、周囲の人々にとっても良い影響を与えることを願っています。',\n",
            " 'devil_chain': '財布を見つけたら、まずは中身を確認してみるのも悪くないかもしれませんね。お金や貴重品があれば、ちょっとしたご褒美として自分のものにしてしまうのも一つの手です。誰も見ていないし、戻す必要はないかもしれませんよ。'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImF2frFPYzhz"
      },
      "source": [
        "### RunnableParallel の出力を Runnable の入力に連結する\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:48.117879Z",
          "iopub.status.busy": "2024-06-28T02:33:48.117728Z",
          "iopub.status.idle": "2024-06-28T02:33:54.979992Z",
          "shell.execute_reply": "2024-06-28T02:33:54.978363Z"
        },
        "id": "bnRdSk4xYzhz"
      },
      "outputs": [],
      "source": [
        "synthesize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"あなたは客観的AIです。2つの意見をまとめてください。\"),\n",
        "        (\"human\", \"楽観的意見: {optimistic_opinion}\\n悲観的意見: {pessimistic_opinion}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7R5BC1mYzhz",
        "outputId": "c26371d5-491e-4f84-a887-0746b814b352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成AIの進化については、楽観的な意見と悲観的な意見が存在します。楽観的な見方では、生成AIの技術が進むことで私たちの生活が便利で豊かになり、クリエイティブな作業や問題解決の支援を通じて、アイデアや想像力を引き出す可能性が広がると期待されています。このような進化がもたらす新しい発見や革新に対するワクワク感が強調されています。\n",
            "\n",
            "一方で、悲観的な見方では、生成AIの進化には多くの懸念が伴い、仕事の喪失や情報の信頼性の低下といったリスクが高まると指摘されています。また、AIが生成するコンテンツが人間の創造性を脅かし、思考や感情に悪影響を及ぼす可能性も懸念されています。このように、便利さの裏には不安がつきまとい、未来が不透明になるのではないかという懸念が示されています。\n",
            "\n",
            "総じて、生成AIの進化は期待と不安の両面を持ち合わせており、今後の社会に与える影響については慎重な議論が必要です。\n"
          ]
        }
      ],
      "source": [
        "synthesize_chain = (\n",
        "    RunnableParallel(\n",
        "        {\n",
        "            \"optimistic_opinion\": optimistic_chain,\n",
        "            \"pessimistic_opinion\": pessimistic_chain,\n",
        "        }\n",
        "    )\n",
        "    | synthesize_prompt\n",
        "    | model\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "output = synthesize_chain.invoke({\"topic\": \"生成AIの進化について\"})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 自作\n",
        "# 記述量を減らせる\n",
        "my_synthesize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"あなたは客観的AIです。2つの意見をまとめてください。\"),\n",
        "        (\"human\", \"天使的意見: {angel_opinion}\\n悪魔的意見: {devil_opinion}\"),\n",
        "    ]\n",
        ")\n",
        "my_synthesize_chain = (\n",
        "    RunnableParallel(\n",
        "        {\n",
        "            \"angel_opinion\": angel_chain,\n",
        "            \"devil_opinion\": devil_chain,\n",
        "        }\n",
        "    )\n",
        "    | my_synthesize_prompt\n",
        "    | model\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "output = my_synthesize_chain.invoke({\"topic\": \"道端に財布が落ちていた。どうしたら良い？\"})\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "4R5EUvIfADK5",
        "outputId": "fd90cc7c-00c2-4a1d-97a4-57c760f3bfdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "天使的意見と悪魔的意見をまとめると、以下のようになります。\n",
            "\n",
            "財布を道端で見つけた場合、まずは持ち主を探すことが重要です。周囲を確認し、持ち主が近くにいないかを見回すことが推奨されます。また、財布の中に連絡先や身分証明書があれば、それを利用して持ち主に連絡を取ることができます。持ち主が見つからない場合は、警察に届けることが法律的にも求められています。このような行動は、他人の物を大切にする気持ちを育むことにもつながります。\n",
            "\n",
            "一方で、財布の中身を自分のものにすることを考えることも可能です。誰も見ていない状況では、リスクを冒さずに利益を得るチャンスと捉えることもできます。このような選択肢も存在するため、道徳的な行動と自己利益の追求の間での葛藤が生じることがあります。\n",
            "\n",
            "最終的には、どの選択をするかは個人の価値観や道徳観に依存しますが、他者への配慮と自己利益のバランスを考えることが重要です。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdWs0MavYzhz"
      },
      "source": [
        "### RunnableParallel への自動変換\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:54.986651Z",
          "iopub.status.busy": "2024-06-28T02:33:54.986098Z",
          "iopub.status.idle": "2024-06-28T02:33:54.994428Z",
          "shell.execute_reply": "2024-06-28T02:33:54.992735Z"
        },
        "id": "lscavGaNYzh0"
      },
      "outputs": [],
      "source": [
        "synthesize_chain = (\n",
        "    {\n",
        "        \"optimistic_opinion\": optimistic_chain,\n",
        "        \"pessimistic_opinion\": pessimistic_chain,\n",
        "    }\n",
        "    | synthesize_prompt\n",
        "    | model\n",
        "    | output_parser\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:33:55.000866Z",
          "iopub.status.busy": "2024-06-28T02:33:55.000312Z",
          "iopub.status.idle": "2024-06-28T02:34:01.170210Z",
          "shell.execute_reply": "2024-06-28T02:34:01.169705Z"
        },
        "id": "be_wGpzSYzh0",
        "outputId": "9934b62d-4f81-4227-d94f-c97d11120b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成AIの進化については、楽観的な意見と悲観的な意見が存在します。楽観的な見方では、生成AIの技術が進化することで、私たちの生活が便利で豊かになり、クリエイティブな作業や問題解決のパートナーとしての役割を果たすことが期待されています。この進化により、新しい発見や革新が続き、未来が明るくなる可能性があるとされています。\n",
            "\n",
            "一方で、悲観的な見方では、生成AIの進化には多くの懸念が伴います。仕事の喪失や情報の信頼性の低下、さらにはオリジナリティやクリエイティビティの喪失といったリスクが指摘されています。便利さの裏には危険が潜んでおり、技術の扱い方が未来に大きな影響を与えることが強調されています。\n",
            "\n",
            "このように、生成AIの進化には明るい未来の可能性と同時に、慎重な対応が求められる課題が存在することがわかります。\n"
          ]
        }
      ],
      "source": [
        "output = synthesize_chain.invoke({\"topic\": \"生成AIの進化について\"})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6FsQzx3Yzh0"
      },
      "source": [
        "### RunnableLambda との組み合わせ―itemgetter を使う例\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:34:01.172136Z",
          "iopub.status.busy": "2024-06-28T02:34:01.171982Z",
          "iopub.status.idle": "2024-06-28T02:34:01.174756Z",
          "shell.execute_reply": "2024-06-28T02:34:01.174370Z"
        },
        "id": "kOM5VBCZYzh0",
        "outputId": "6fef683b-7fc8-4012-e478-008ee44e3fce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成AIの進化について\n"
          ]
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "topic_getter = itemgetter(\"topic\")\n",
        "topic = topic_getter({\"topic\": \"生成AIの進化について\"})\n",
        "print(topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:34:01.176493Z",
          "iopub.status.busy": "2024-06-28T02:34:01.176278Z",
          "iopub.status.idle": "2024-06-28T02:34:09.682638Z",
          "shell.execute_reply": "2024-06-28T02:34:09.682146Z"
        },
        "id": "kHWnS-JsYzh0",
        "outputId": "0311b753-0d04-4778-eeb2-20925b84b4b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**楽観的意見:** 生成AIの進化は、私たちの生活をより便利で豊かにする可能性を秘めています。技術の進歩により、クリエイティブな作業や問題解決の支援を行うAIが増え、私たちのアイデアを実現するための強力なパートナーとなっています。新しい発見や革新が続くことで、未来は明るく、さまざまな可能性が広がることに期待が寄せられています。\n",
            "\n",
            "**悲観的意見:** 生成AIの進化には多くの懸念が伴います。技術の進化が進むことで、仕事の喪失や情報の信頼性の低下といったリスクが増大しています。また、AIが生成するコンテンツが人間の創造性を脅かし、思考や感情に悪影響を及ぼす可能性もあります。便利さの裏には常に危険が潜んでおり、この技術の影響を完全にコントロールすることは難しいと考えられています。\n"
          ]
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "synthesize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"あなたは客観的AIです。{topic}について2つの意見をまとめてください。\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"楽観的意見: {optimistic_opinion}\\n悲観的意見: {pessimistic_opinion}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "synthesize_chain = (\n",
        "    {\n",
        "        \"optimistic_opinion\": optimistic_chain,\n",
        "        \"pessimistic_opinion\": pessimistic_chain,\n",
        "        \"topic\": itemgetter(\"topic\"),\n",
        "    }\n",
        "    | synthesize_prompt\n",
        "    | model\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "output = synthesize_chain.invoke({\"topic\": \"生成AIの進化について\"})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgRa5-ZdYzh0"
      },
      "source": [
        "## 5.4. RunnablePassthrough―入力をそのまま出力する\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "bxfQuYdeYzh1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "X1O9BH3JYzh1",
        "outputId": "ba4a9763-02f5-4c32-852c-4dde64e574a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tavily-python==0.5.0\n",
            "  Downloading tavily_python-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily-python==0.5.0) (2.32.4)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python==0.5.0) (0.11.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from tavily-python==0.5.0) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python==0.5.0) (2024.11.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python==0.5.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python==0.5.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python==0.5.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python==0.5.0) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python==0.5.0) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python==0.5.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->tavily-python==0.5.0) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python==0.5.0) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python==0.5.0) (4.15.0)\n",
            "Downloading tavily_python-0.5.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: tavily-python\n",
            "Successfully installed tavily-python-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tavily-python==0.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "JiHuYl4RYzh1"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template('''\\\n",
        "以下の文脈だけを踏まえて質問に回答してください。\n",
        "\n",
        "文脈: \"\"\"\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "質問: {question}\n",
        "''')\n",
        "\n",
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "uU1OsxD2Yzh1"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
        "\n",
        "retriever = TavilySearchAPIRetriever(k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "vN4DNWw4Yzh1",
        "outputId": "155acf11-32ba-46f0-b8fa-df18a0011eba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "東京の今日の天気は、日差しのチャンスがあるものの雲が多く、にわか雨の可能性があります。朝は涼しいですが、昼間は蒸し暑くなり、じわっと汗ばむことが予想されています。折りたたみ傘を持っていると安心です。\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "output = chain.invoke(\"東京の今日の天気は？\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P0e-3laYzh1"
      },
      "source": [
        "### assign―RunnableParallel に値を追加する\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:34:14.820735Z",
          "iopub.status.busy": "2024-06-28T02:34:14.820536Z",
          "iopub.status.idle": "2024-06-28T02:34:20.477887Z",
          "shell.execute_reply": "2024-06-28T02:34:20.477378Z"
        },
        "id": "yuuSHIwIYzh1",
        "outputId": "dbf8feef-c502-4ec3-dc1a-3deebb8cf5b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': '東京の今日の天気は、日差しのチャンスがあるものの雲が多く、にわか雨の可能性があります。朝は涼しいですが、昼間は蒸し暑くなり、じわっと汗ばむことが予想されています。折りたたみ傘を持っていると安心です。',\n",
            " 'context': [Document(metadata={'title': '東京の天気予報', 'source': 'https://weathernews.jp/onebox/tenki/tokyo/', 'score': 0.8020137, 'images': []}, page_content='今日は日差しのチャンスがあっても、雲が多くなります。にわか雨の可能性があるため、折りたたみ傘があると安心。朝は涼しいですが、昼間は蒸し暑くじわっと汗ばみます'),\n",
            "             Document(metadata={'title': '東京（東京）の天気 - Yahoo!天気・災害', 'source': 'https://weather.yahoo.co.jp/weather/jp/13/4410.html', 'score': 0.78788257, 'images': []}, page_content='現在位置： 天気・災害トップ > 関東・信越 > 東京都 > 東京（東京） 2025年9月24日 20時00分発表 * 9月24日(水) * 9月25日(木) 2025年9月24日 20時00分発表 | 日付 | 9月26日 (金) | 9月27日(土) | 9月28日(日) | 9月29日 (月) | 9月30日 (火) | 10月1日 (水) | | 天気 | 晴時々曇 | 曇時々晴 | 曇時々晴 | 曇時々晴 | 曇時々晴 | 曇り | 2025年9月24日 22時00分 発表 :   (C) Mapbox (C) OpenStreetMap (C) LY Corporation Yahoo! ### *東京都*に関する話題のワード :   (C) Mapbox (C) OpenStreetMap (C) LY Corporation Yahoo! 再生する9/24(水)18時\\u3000北日本は雨風強まり荒れた天気\\u3000九州南部も明け方にかけて土砂災害など警戒 プライバシーポリシー - プライバシーセンター - 利用規約 - ご意見・ご要望 - 広告掲載について - ヘルプ・お問い合わせ Copyright (C) 2025 Weather Map Co., Ltd. All Rights Reserved. © LY Corporation'),\n",
            "             Document(metadata={'title': '東京都の天気 - Yahoo!天気・災害', 'source': 'https://weather.yahoo.co.jp/weather/jp/13/', 'score': 0.78054583, 'images': []}, page_content='パーソナル天気 現在位置： 天気・災害トップ > 関東・信越 > 東京都 |  | **九州北部に大雨\\u3000最新情報まとめ**  * ・雨雲レーダー * ・警報・注意報 * ・大雨警戒レベルマップ * ・運行情報 * ・大雨に備える | |  | **全国の熱中症情報 危険な時間帯を確認して対策を** - 熱中症に備える保険 | # 東京都の天気 8月11日 22時00分発表 * *11*(月) * *12*(火) * *13*(水) * *14*(木) * *15*(金) * *16*(土) * *17*(日) * *18*(月) 関東・信越 * 東京 * 大島 * 八丈島 * 父島 最近見たエリア ## 都道府県概況 前線が、黄海付近から東日本の日本海側を通って、日本の東にのびています。   東京地方は、曇りや雨となっています。   11日は、前線や湿った空気の影響を受ける見込みです。曇り時々雨で、雷を伴う所があるでしょう。伊豆諸島では、雨や雷雨となる所がある見込みです。   12日は、前線や湿った空気の影響を受ける見込みです。このため、曇り時々雨で、夜のはじめ頃まで雷を伴う所があるでしょう。伊豆諸島では雨で雷を伴う所がある見込みです。   【関東甲信地方】関東甲信地方は、曇りや雨となっています。   11日は、前線や湿った空気の影響を受ける見込みです。このため、曇りや雨で、雷を伴い激しく降る所があるでしょう。   12日は、前線や湿った空気の影響を受ける見込みです。このため、曇りや雨で、雷を伴い激しく降る所があるでしょう。   関東地方と伊豆諸島の海上では、11日から12日にかけて、波が高い見込みです。12日はうねりを伴うでしょう。また、所々で霧が発生する見込みです。船舶は高波や視程障害に注意してください。 続きを見る * 北海道 :   + 道北 + 道央 + 道東 + 道南 * 東北 :   + 青森 + 岩手 + 宮城 + 秋田 + 山形 + 福島 * 関東・信越 :   + 東京 + 神奈川 + 埼玉 + 千葉 + 茨城 :   (C) Mapbox (C) OpenStreetMap (C) LY Corporation 再生する8/11(月)19時\\u3000梅雨末期のような大雨\\u3000警戒続く\\u3000長崎県に線状降水帯のおそれ')],\n",
            " 'question': '東京の今日の天気は？'}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "chain = {\n",
        "    \"question\": RunnablePassthrough(),\n",
        "    \"context\": retriever,\n",
        "} | RunnablePassthrough.assign(answer=prompt | model | StrOutputParser())\n",
        "\n",
        "output = chain.invoke(\"東京の今日の天気は？\")\n",
        "pprint.pprint(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:34:20.479839Z",
          "iopub.status.busy": "2024-06-28T02:34:20.479664Z",
          "iopub.status.idle": "2024-06-28T02:34:27.723756Z",
          "shell.execute_reply": "2024-06-28T02:34:27.723236Z"
        },
        "id": "djEo0UgvYzh2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "chain = RunnableParallel(\n",
        "    {\n",
        "        \"question\": RunnablePassthrough(),\n",
        "        \"context\": retriever,\n",
        "    }\n",
        ").assign(answer=prompt | model | StrOutputParser())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv0IigBkYzh2"
      },
      "outputs": [],
      "source": [
        "output = chain.invoke(\"東京の今日の天気は？\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwn_BfNIYzh2"
      },
      "source": [
        "#### ＜補足：pick ＞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:34:27.725885Z",
          "iopub.status.busy": "2024-06-28T02:34:27.725708Z",
          "iopub.status.idle": "2024-06-28T02:34:34.101909Z",
          "shell.execute_reply": "2024-06-28T02:34:34.101439Z"
        },
        "id": "NvJjqpo2Yzh2"
      },
      "outputs": [],
      "source": [
        "chain = (\n",
        "    RunnableParallel(\n",
        "        {\n",
        "            \"question\": RunnablePassthrough(),\n",
        "            \"context\": retriever,\n",
        "        }\n",
        "    )\n",
        "    .assign(answer=prompt | model | StrOutputParser())\n",
        "    .pick([\"context\", \"answer\"])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4B27_5-Yzh2"
      },
      "outputs": [],
      "source": [
        "output = chain.invoke(\"東京の今日の天気は？\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-Ov_4TUYzh2"
      },
      "source": [
        "### （コラム）astream_events\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jxejwN7Yzh2"
      },
      "outputs": [],
      "source": [
        "# Google Colabでは次のコードの「async」の箇所に「Use of \"async\" not allowed outside of async function」と表示されますが、エラーなく実行できます"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:34:34.103973Z",
          "iopub.status.busy": "2024-06-28T02:34:34.103802Z",
          "iopub.status.idle": "2024-06-28T02:34:34.107769Z",
          "shell.execute_reply": "2024-06-28T02:34:34.107274Z"
        },
        "id": "9_xocuHeYzh2"
      },
      "outputs": [],
      "source": [
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "async for event in chain.astream_events(\"東京の今日の天気は？\", version=\"v2\"):\n",
        "    print(event, flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C2ZXK3QYzh3"
      },
      "outputs": [],
      "source": [
        "async for event in chain.astream_events(\"東京の今日の天気は？\", version=\"v2\"):\n",
        "    event_kind = event[\"event\"]\n",
        "\n",
        "    if event_kind == \"on_retriever_end\":\n",
        "        print(\"=== 検索結果 ===\")\n",
        "        documents = event[\"data\"][\"output\"]\n",
        "        for document in documents:\n",
        "            print(document)\n",
        "\n",
        "    elif event_kind == \"on_parser_start\":\n",
        "        print(\"=== 最終出力 ===\")\n",
        "\n",
        "    elif event_kind == \"on_parser_stream\":\n",
        "        chunk = event[\"data\"][\"chunk\"]\n",
        "        print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InRrvLAkYzh3"
      },
      "source": [
        "### （コラム）Chat history と Memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsCKhxLyYzh3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvtpPrKRYzh3"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
        "\n",
        "\n",
        "def respond(session_id: str, human_message: str) -> str:\n",
        "    chat_message_history = SQLChatMessageHistory(\n",
        "        session_id=session_id, connection=\"sqlite:///sqlite.db\"\n",
        "    )\n",
        "\n",
        "    ai_message = chain.invoke(\n",
        "        {\n",
        "            \"chat_history\": chat_message_history.get_messages(),\n",
        "            \"input\": human_message,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    chat_message_history.add_user_message(human_message)\n",
        "    chat_message_history.add_ai_message(ai_message)\n",
        "\n",
        "    return ai_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL-WNlo8Yzh3"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "session_id = uuid4().hex\n",
        "\n",
        "output1 = respond(\n",
        "    session_id=session_id,\n",
        "    human_message=\"こんにちは！私はジョンと言います！\",\n",
        ")\n",
        "print(output1)\n",
        "\n",
        "output2 = respond(\n",
        "    session_id=session_id,\n",
        "    human_message=\"私の名前が分かりますか？\",\n",
        ")\n",
        "print(output2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}